{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e1376b08a5ca41ad978d0580b8a346f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "DSMIL",
              "ABMIL",
              "MaxPooling",
              "MeanPooling",
              "TransMIL",
              "Buffermil"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Choose:",
            "description_tooltip": null,
            "disabled": false,
            "index": 2,
            "layout": "IPY_MODEL_294cfe85793a4572b11970ab32b951fb",
            "style": "IPY_MODEL_d87d580e7dd5425b8e38239bc9f7ddcd"
          }
        },
        "294cfe85793a4572b11970ab32b951fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d87d580e7dd5425b8e38239bc9f7ddcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title Download Camelyon16 embeddings\n",
        "!curl -o dataset.zip https://ailb-web.ing.unimore.it/publicfiles/miccai_dasmil_checkpoints/cam_feats.zip\n",
        "!unzip dataset.zip"
      ],
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "nT-8ebdcmy3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Prepare Environment\n",
        "import torch\n",
        "import os\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "!pip install nystrom-attention\n",
        "!git clone https://github.com/aimagelab/mil4wsi.git\n",
        "!cd mil4wsi"
      ],
      "metadata": {
        "cellView": "form",
        "id": "aLAzr4Lgq8qV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load Libraries\n",
        "from torch_geometric.data import Dataset\n",
        "import glob\n",
        "from torch_geometric.data import data\n",
        "from torch_geometric.loader import DataLoader\n",
        "import sys\n",
        "sys.path.append(\"/content/mil4wsi\")\n",
        "from utilsmil4wsi.test import test\n",
        "import argparse\n",
        "from models import selectModel\n",
        "import wandb\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "import torch\n",
        "import os\n",
        "import wandb\n",
        "from argparse import Namespace\n",
        "import time\n",
        "import tqdm"
      ],
      "metadata": {
        "cellView": "form",
        "id": "u_vvp7czG1RM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_root=\"camGraph_23/processed\""
      ],
      "metadata": {
        "id": "V9jrhrVRnvQF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self,root,data_type):\n",
        "        self.path=os.path.join(root,data_type,\"*\")\n",
        "        self.data=glob.glob(self.path)\n",
        "        print(self.data)\n",
        "        self.slides=[torch.load(self.data[idx]) for idx in range(len(self.data))]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.slides[idx]\n",
        "        return sample\n",
        "train_dataset=CustomDataset(data_root,\"train\")\n",
        "test_dataset=CustomDataset(data_root,\"test\")\n",
        "train_loader=DataLoader(train_dataset,batch_size=1,shuffle=True)\n",
        "test_loader=DataLoader(test_dataset,batch_size=1,shuffle=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wzRsNcLqnnTm"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title General Parser\n",
        "def get_args():\n",
        "    parser = argparse.ArgumentParser(description='TRAIN DASMIL')\n",
        "\n",
        "    # Optimization arguments\n",
        "    group1 = parser.add_argument_group(\"optimization\")\n",
        "    group1.add_argument('--lr', default=0.0002,\n",
        "                        type=float, help='learning rate')\n",
        "    group1.add_argument('--weight_decay', default=0.00001,\n",
        "                        type=float, help='Weight decay [5e-3]')\n",
        "\n",
        "    # GNN arguments\n",
        "    group2 = parser.add_argument_group(\"gnn\")\n",
        "    group2.add_argument('--residual', default=False, action=\"store_true\",)\n",
        "    group2.add_argument('--num_layers', default=1, type=int,\n",
        "                        help='number of Graph layers')\n",
        "    group2.add_argument('--dropout', default=True, action=\"store_true\")\n",
        "    group2.add_argument('--dropout_rate', default=0.2, type=float)\n",
        "    group2.add_argument('--layer_name', default=\"GAT\",\n",
        "                        type=str, help='layer graph name')\n",
        "    group2.add_argument('--heads', default=3, type=int,\n",
        "                        help='layer graph name')\n",
        "\n",
        "    # Training arguments\n",
        "    group3 = parser.add_argument_group(\"training\")\n",
        "    group3.add_argument('--seed', default=12, type=int,\n",
        "                        help='seed for reproducibility')\n",
        "    group3.add_argument('--n_epoch', default=200,\n",
        "                        type=int, help='number of epochs')\n",
        "\n",
        "    # Dimensions arguments\n",
        "    group4 = parser.add_argument_group(\"dimensions\")\n",
        "    group4.add_argument('--n_classes', default=1, type=int,\n",
        "                        help='Number of output classes [2]')\n",
        "    group4.add_argument('--c_hidden', default=256,\n",
        "                        type=int, help='intermediate size ')\n",
        "    group4.add_argument('--input_size', default=384,\n",
        "                        type=int, help='input size ')\n",
        "\n",
        "    # Dataset arguments\n",
        "    group5 = parser.add_argument_group(\"dataset\")\n",
        "    group5.add_argument('--scale', default=\"1\", type=str,\n",
        "                        help='scale resolution')\n",
        "    group5.add_argument('--dataset', default=\"cam\", type=str,\n",
        "                        choices=[\"cam\", \"lung\"], help='input size ')\n",
        "    group5.add_argument('--datasetpath',  type=str, help='dataset path')\n",
        "\n",
        "    # Distillation arguments\n",
        "    group6 = parser.add_argument_group(\"distillation\")\n",
        "    group6.add_argument('--lamb', default=1, type=float, help='lambda')\n",
        "    group6.add_argument('--beta', default=1, type=float, help='beta')\n",
        "    group6.add_argument('--temperature', default=1.5, type=float, help='temperature')\n",
        "    group6.add_argument('--add_bias', default=True,action=\"store_true\")\n",
        "    group6.add_argument('--max', default=True,action=\"store_true\")\n",
        "    group6.add_argument('--checkpoint', default=None,type=str, help='checkpoint')\n",
        "\n",
        "    parser.add_argument('--tag', default=\"split\", type=str, help='train strategy')\n",
        "    parser.add_argument('--modeltype', default=\"DSMIL\", type=str, help='train strategy')\n",
        "    parser.add_argument('--project', default=\"decider-geom\", type=str, help='project name for wandb')\n",
        "    parser.add_argument('--model', default=\"decider-geom\", type=str, help='project name for wandb')\n",
        "    parser.add_argument('--wandbname', default=\"main\", type=str, help='project name for wandb')\n",
        "\n",
        "\n",
        "    group7= parser.add_argument_group(\"submitit\")\n",
        "    group7.add_argument('--partition', default=\"prod\",type=str,help='partition name')\n",
        "    group7.add_argument('--time', default=120, type=float, help='job duration')\n",
        "    group7.add_argument('--nodes', default=1, type=int, help='number of jobs')\n",
        "    group7.add_argument('--job_name', default=\"dasmil\",type=str,help=\"job name\")\n",
        "    group7.add_argument('--mem', default=32, type=int, help='ram requested GB')\n",
        "    group7.add_argument('--job_parallel', default=10, type=int, help='number of jobs in parallel')\n",
        "    group7.add_argument('--logfolder', default=\"logfolder\", type=str, help='log folder location name')\n",
        "\n",
        "\n",
        "    #buffermil parameters\n",
        "    group8= parser.add_argument_group(\"submitit\")\n",
        "\n",
        "    group8.add_argument(\"--randomstore\", default=False,help=\"ramdom sampling during the buffer storage\")\n",
        "    group8.add_argument(\"--bufferaggregate\", default=\"mean\",choices=[\"mean\",\"max\",\"diffmax\"], help=\"type of buffer aggregation\")\n",
        "    group8.add_argument(\"--ntop\", default=10, help=\"number of patches stored in the buffer per each image\")\n",
        "    group8.add_argument('--buffer_freq',default=10, type=int, help='frequency to update the buffer')\n",
        "    filtered_args = [arg for arg in sys.argv if not arg.startswith('-f')]\n",
        "    args = parser.parse_args(filtered_args[2:])\n",
        "    return args"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LaLCA3s3y41l"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args= get_args()\n",
        "print(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-SVOmf4xcIQ",
        "outputId": "1893d558-2f09-4c28-c235-424443c46735"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(lr=0.0002, weight_decay=0.005, residual=False, num_layers=1, dropout=True, dropout_rate=0.2, layer_name='GAT', heads=3, seed=12, n_epoch=200, n_classes=1, c_hidden=256, input_size=384, scale='1', dataset='cam', datasetpath=None, lamb=1, beta=1, temperature=1.5, add_bias=True, max=True, checkpoint=None, tag='split', modeltype='DSMIL', project='decider-geom', model='decider-geom', wandbname='main', partition='prod', time=120, nodes=1, job_name='dasmil', mem=32, job_parallel=10, logfolder='logfolder', randomstore=False, bufferaggregate='mean', ntop=10, buffer_freq=10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Select Model\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Crea un menu a discesa\n",
        "dropdown = widgets.Dropdown(\n",
        "\n",
        "    options=['DSMIL', 'ABMIL', 'MaxPooling',\"MeanPooling\",\"TransMIL\",\"Buffermil\"],\n",
        "    value='DSMIL',\n",
        "    description='Choose:',\n",
        ")\n",
        "\n",
        "# Mostra il widget\n",
        "display(dropdown)\n",
        "\n",
        "# Recupera il valore selezionato\n",
        "def on_value_change(change):\n",
        "    print(f\"Selected: {change['new']}\")\n",
        "\n",
        "dropdown.observe(on_value_change, names='value')\n",
        "args.modeltype=dropdown.value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "e1376b08a5ca41ad978d0580b8a346f7",
            "294cfe85793a4572b11970ab32b951fb",
            "d87d580e7dd5425b8e38239bc9f7ddcd"
          ]
        },
        "cellView": "form",
        "id": "_Vpuvd0xIHWk",
        "outputId": "a475c5a1-5c8f-4a70-9e92-7edf301c1dc0"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Choose:', options=('DSMIL', 'ABMIL', 'MaxPooling', 'MeanPooling', 'TransMIL', 'Buffermil…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1376b08a5ca41ad978d0580b8a346f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected: ABMIL\n",
            "Selected: MaxPooling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=selectModel(args)\n",
        "model.kl=None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deS1EoTF0G6A",
        "outputId": "7c513263-1ce4-4435-97a4-09b736ef0d8c"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model MaxPooling\n",
            "error loading\n",
            "Number of parameters: 385\n",
            "Memory usage: 0.104024576 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Training Method\n",
        "def train(model,train_loader,test_loader,args):\n",
        "   # Initialize wandb run\n",
        "    run = wandb.init(project=\"MIL\",name=args.modeltype)\n",
        "    epochs = args.n_epoch\n",
        "    wd=args.weight_decay\n",
        "    lr=args.lr\n",
        "    model.train()\n",
        "    model = model.cuda()\n",
        "    loss_module_instance = BCEWithLogitsLoss()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(\n",
        "        0.5, 0.9), weight_decay=wd)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs, 0.000005)\n",
        "    # Test the initial model\n",
        "    with torch.no_grad():\n",
        "        start_test = time.time()\n",
        "        metrics = test(model, testloader=test_loader)\n",
        "        end_test = time.time()\n",
        "        avg_score_higher_test, avg_score_lower_test, auc_value_higher_test, auc_value_lower_test, predictions, _, labels = metrics\n",
        "\n",
        "        wandb.log({\n",
        "            \"acc_higher_test\": avg_score_higher_test,\n",
        "            \"acc_lower_test\": avg_score_lower_test,\n",
        "            \"auc_higher_test\": auc_value_higher_test,\n",
        "            \"epoch\": -1,\n",
        "            \"lr\": scheduler.get_last_lr()[0]\n",
        "        })\n",
        "    BestPerformance = 0\n",
        "    # Start training\n",
        "    for idx,epoch in tqdm.tqdm(enumerate(range(epochs)),desc=\"epochs\"):\n",
        "        start_training = time.time()\n",
        "        if hasattr(model,\"preloop\"):\n",
        "            model.preloop(epoch,train_loader)\n",
        "        # Iterate over the training data\n",
        "        for _, data in enumerate(train_loader):\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            data = data.cuda()\n",
        "            x, edge_index, childof, level = data.x, data.edge_index, data.childof, data.level\n",
        "            # Check if additional edge indices are present\n",
        "            if data.__contains__(\"edge_index_2\") and data.__contains__(\"edge_index_3\"):\n",
        "                edge_index2, edge_index3 = data.edge_index_2, data.edge_index_3\n",
        "            else:\n",
        "                edge_index2 = None\n",
        "                edge_index3 = None\n",
        "\n",
        "            try:\n",
        "                results = model(x, edge_index, level, childof,edge_index2, edge_index3)\n",
        "            except:\n",
        "                continue\n",
        "            bag_label = data.y.float()\n",
        "            loss = model.compute_loss(loss_module_instance, results, bag_label)\n",
        "            wandb.log({\"loss\": loss})\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        end_training = time.time()\n",
        "        scheduler.step()\n",
        "        start_test = time.time()\n",
        "        metrics = test(model, testloader=test_loader)\n",
        "        end_test = time.time()\n",
        "        avg_score_higher_test, avg_score_lower_test, auc_value_higher_test, auc_value_lower_test, predictions, _, labels = metrics\n",
        "\n",
        "        wandb.log({\n",
        "            \"acc_higher_test\": avg_score_higher_test,\n",
        "            \"acc_lower_test\": avg_score_lower_test,\n",
        "            \"auc_higher_test\": auc_value_higher_test,\n",
        "            \"epoch\": epoch,\n",
        "            \"lr\": scheduler.get_last_lr()[0]\n",
        "        })\n",
        "\n",
        "    wandb.finish()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6gyKkA8kvQac"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Start Training\n",
        "train(model,train_loader,test_loader,args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "oTV2Lel34bci",
        "outputId": "ea58585a-8b76-45c4-ddc2-84608f1bd3f5"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:wfbti96l) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc_higher_test</td><td>▅▇▅▇▅▂▆▅█▇▄▄█▇▇▄▆▄▆▁▄▇▂▇▆▄▆▆▄▇▇▇▇▆▇█▇▆▆▃</td></tr><tr><td>acc_lower_test</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>auc_higher_test</td><td>▁▆▆▇▇▇▇▇▇▇▆▇▇██████▅▇▇▇█▇▇▇▇▇▇█▇▇▇▇▇██▇▇</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▁██▇███████████████████████████▇████▇███</td></tr><tr><td>lr</td><td>███████████▇▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▂▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc_higher_test</td><td>0.60156</td></tr><tr><td>acc_lower_test</td><td>0</td></tr><tr><td>auc_higher_test</td><td>0.67982</td></tr><tr><td>epoch</td><td>46</td></tr><tr><td>loss</td><td>1.37711</td></tr><tr><td>lr</td><td>0.00017</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">ABMIL</strong> at: <a href='https://wandb.ai/gbont/MIL/runs/wfbti96l' target=\"_blank\">https://wandb.ai/gbont/MIL/runs/wfbti96l</a><br/> View project at: <a href='https://wandb.ai/gbont/MIL' target=\"_blank\">https://wandb.ai/gbont/MIL</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241115_182406-wfbti96l/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:wfbti96l). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241115_182852-1mpxv90g</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/gbont/MIL/runs/1mpxv90g' target=\"_blank\">DSMIL</a></strong> to <a href='https://wandb.ai/gbont/MIL' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/gbont/MIL' target=\"_blank\">https://wandb.ai/gbont/MIL</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/gbont/MIL/runs/1mpxv90g' target=\"_blank\">https://wandb.ai/gbont/MIL/runs/1mpxv90g</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epochs: 109it [11:29,  6.33s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-9235f0278b8f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-81-5a5def6bd45b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, test_loader, args)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_module_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbag_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mend_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}